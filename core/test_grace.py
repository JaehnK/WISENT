"""
GRACE (GRAph-based Clustering with Enhanced embeddings) í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš© ì˜ˆì‹œ:
python test_grace.py --documents 500 --clusters 10
python test_grace.py --documents 1000 --epochs 100 --auto-cluster
"""

import argparse
from services.GRACE import GRACEPipeline, GRACEConfig


def parse_args():
    parser = argparse.ArgumentParser(description='GRACE íŒŒì´í”„ë¼ì¸ ì‹¤í–‰')

    # ë°ì´í„° ì„¤ì •
    parser.add_argument('--csv', type=str,
                        default='/home/jaehun/lab/SENTIMENT/kaggle_RC_2019-05.csv',
                        help='CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--documents', type=int, default=500,
                        help='ì‚¬ìš©í•  ë¬¸ì„œ ìˆ˜')
    parser.add_argument('--top-words', type=int, default=500,
                        help='ìƒìœ„ ë‹¨ì–´ ìˆ˜ (ë…¸ë“œ)')

    # ì„ë² ë”© ì„¤ì •
    parser.add_argument('--embed-method', type=str, default='concat',
                        choices=['concat', 'w2v', 'bert'],
                        help='ì„ë² ë”© ë°©ë²•')
    parser.add_argument('--embed-size', type=int, default=64,
                        help='ì„ë² ë”© ì°¨ì›')

    # GraphMAE ì„¤ì •
    parser.add_argument('--epochs', type=int, default=100,
                        help='GraphMAE í•™ìŠµ ì—í¬í¬')
    parser.add_argument('--lr', type=float, default=0.001,
                        help='Learning rate')
    parser.add_argument('--mask-rate', type=float, default=0.75,
                        help='GraphMAE mask rate')

    # í´ëŸ¬ìŠ¤í„°ë§ ì„¤ì •
    parser.add_argument('--clusters', type=int, default=None,
                        help='í´ëŸ¬ìŠ¤í„° ìˆ˜ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ìë™ íƒìƒ‰)')
    parser.add_argument('--auto-cluster', action='store_true',
                        help='ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ìë™ íƒìƒ‰')
    parser.add_argument('--min-clusters', type=int, default=3,
                        help='ìµœì†Œ í´ëŸ¬ìŠ¤í„° ìˆ˜ (ìë™ íƒìƒ‰ ì‹œ)')
    parser.add_argument('--max-clusters', type=int, default=20,
                        help='ìµœëŒ€ í´ëŸ¬ìŠ¤í„° ìˆ˜ (ìë™ íƒìƒ‰ ì‹œ)')

    # ì¶œë ¥ ì„¤ì •
    parser.add_argument('--output-dir', type=str, default='./grace_output',
                        help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--no-save', action='store_true',
                        help='ê²°ê³¼ ì €ì¥ ì•ˆ í•¨')
    parser.add_argument('--quiet', action='store_true',
                        help='ë¡œê·¸ ì¶œë ¥ ì•ˆ í•¨')

    return parser.parse_args()


def main():
    args = parse_args()

    # ì„¤ì • ìƒì„±
    config = GRACEConfig(
        # ë°ì´í„°
        csv_path=args.csv,
        num_documents=args.documents,
        top_n_words=args.top_words,

        # ì„ë² ë”©
        embedding_method=args.embed_method,
        embed_size=args.embed_size,
        w2v_dim=32 if args.embed_method == 'concat' else args.embed_size,
        bert_dim=32 if args.embed_method == 'concat' else args.embed_size,

        # GraphMAE
        graphmae_epochs=args.epochs,
        graphmae_lr=args.lr,
        mask_rate=args.mask_rate,

        # í´ëŸ¬ìŠ¤í„°ë§
        num_clusters=None if args.auto_cluster else args.clusters,
        min_clusters=args.min_clusters,
        max_clusters=args.max_clusters,

        # ì¶œë ¥
        output_dir=args.output_dir,
        save_results=not args.no_save,
        verbose=not args.quiet
    )

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = GRACEPipeline(config)
    results = pipeline.run()

    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“Š GRACE ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    print(f"í´ëŸ¬ìŠ¤í„° ìˆ˜: {results['num_clusters']}")
    print(f"\ní‰ê°€ ì§€í‘œ:")
    for metric, value in results['metrics'].items():
        print(f"  {metric}: {value:.4f}")

    print(f"\ní´ëŸ¬ìŠ¤í„°ë³„ ë‹¨ì–´ ìˆ˜:")
    for cluster_id, count in results['cluster_distribution'].items():
        print(f"  Cluster {cluster_id}: {count}ê°œ")

    # ê° í´ëŸ¬ìŠ¤í„°ì˜ ìƒìœ„ ë‹¨ì–´ ì¶œë ¥
    print(f"\ní´ëŸ¬ìŠ¤í„°ë³„ ëŒ€í‘œ ë‹¨ì–´ (ìƒìœ„ 10ê°œ):")
    for cluster_id in sorted(results['clusters'].keys()):
        words = results['clusters'][cluster_id][:10]
        print(f"  Cluster {cluster_id}: {', '.join(words)}")

    # CSV ì €ì¥
    if not args.no_save:
        csv_path = f"{args.output_dir}/clusters.csv"
        pipeline.export_cluster_csv(csv_path)
        print(f"\nğŸ’¾ í´ëŸ¬ìŠ¤í„° ê²°ê³¼ CSV ì €ì¥: {csv_path}")


if __name__ == "__main__":
    main()
