"""
GraphMAE íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ - ë…¼ë¬¸ íë¦„

íŒŒì´í”„ë¼ì¸:
1. ë°ì´í„° ë¡œë“œ (kaggle_RC_2019-05.csv)
2. ë¬¸ì„œ ì „ì²˜ë¦¬ (DocumentService)
3. ê³µì¶œí˜„ ê·¸ë˜í”„ ìƒì„± (ìƒìœ„ 500ê°œ ë‹¨ì–´)
4. ë…¸ë“œ íŠ¹ì„± ê³„ì‚°: Word2Vec(32) + BERT(32) = 64ì°¨ì› concat
5. GraphMAE ì‚¬ì „í•™ìŠµ (ê·¸ë˜í”„ êµ¬ì¡° + ë…¸ë“œ íŠ¹ì„±)
6. í•™ìŠµëœ ì„ë² ë”© ì¶”ì¶œ
7. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”

ë‹¤ìŒ ë‹¨ê³„: ì¶”ì¶œëœ ì„ë² ë”©ìœ¼ë¡œ ë‹¨ì–´ í´ëŸ¬ìŠ¤í„°ë§ (K-Means, DBSCAN ë“±)
"""

import os
import sys
import pandas as pd
import torch
import numpy as np
from typing import List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# í•„ìš”í•œ ëª¨ë“ˆë“¤ import
from services.Document.DocumentService import DocumentService
from services.Graph.GraphService import GraphService
from services.Graph.NodeFeatureHandler import NodeFeatureHandler
from services.GraphMAE import GraphMAEService, GraphMAEConfig
from entities import Word, WordGraph, NodeFeatureType


def load_dataset(csv_path: str, num_documents: int = 1000) -> List[str]:
    """
    CSV ë°ì´í„°ì…‹ ë¡œë“œ

    Args:
        csv_path: CSV íŒŒì¼ ê²½ë¡œ
        num_documents: ë¡œë“œí•  ë¬¸ì„œ ìˆ˜

    Returns:
        ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸ“ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘: {csv_path}")

    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")

    df = pd.read_csv(csv_path)
    print(f"âœ“ ì „ì²´ ë°ì´í„° í¬ê¸°: {len(df)} í–‰")

    # 'body' ì»¬ëŸ¼ì—ì„œ ë¬¸ì„œ ì¶”ì¶œ
    if 'body' not in df.columns:
        raise ValueError("CSV íŒŒì¼ì— 'body' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    # NaN ê°’ ì œê±° ë° ë¬¸ì„œ ì„ íƒ
    documents = df['body'].dropna().head(num_documents).tolist()
    print(f"âœ“ ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(documents)}")

    return documents


def create_graph_service(documents: List[str]) -> GraphService:
    """
    DocumentServiceì™€ GraphService ì´ˆê¸°í™”

    Args:
        documents: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸

    Returns:
        ì´ˆê¸°í™”ëœ GraphService
    """
    print("\nğŸ”§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")

    # DocumentService ì´ˆê¸°í™”
    doc_service = DocumentService()
    print("âœ“ DocumentService ì´ˆê¸°í™” ì™„ë£Œ")

    # ë¬¸ì„œ ì²˜ë¦¬
    doc_service.create_sentence_list(documents=documents)
    print(f"âœ“ ë¬¸ì¥ ì²˜ë¦¬ ì™„ë£Œ - {doc_service.get_sentence_count()}ê°œ ë¬¸ì¥")

    # ë‹¨ì–´ ì²˜ë¦¬ (ë¬¸ì¥ ì²˜ë¦¬ ì‹œ ìë™ ìƒì„±ë¨)
    print(f"âœ“ ë‹¨ì–´ ì²˜ë¦¬ ì™„ë£Œ - {len(doc_service.words_list)}ê°œ ë‹¨ì–´")

    # GraphService ì´ˆê¸°í™”
    graph_service = GraphService(doc_service)
    print("âœ“ GraphService ì´ˆê¸°í™” ì™„ë£Œ")

    return graph_service


def build_cooccurrence_graph(graph_service: GraphService, top_n: int = 500) -> WordGraph:
    """
    ê³µì¶œí˜„ ê·¸ë˜í”„ ìƒì„±

    Args:
        graph_service: GraphService ì¸ìŠ¤í„´ìŠ¤
        top_n: ìƒìœ„ ë‹¨ì–´ ìˆ˜

    Returns:
        ê³µì¶œí˜„ ê·¸ë˜í”„
    """
    print(f"\nğŸ“Š ê³µì¶œí˜„ ê·¸ë˜í”„ ìƒì„± ì¤‘ (ìƒìœ„ {top_n}ê°œ ë‹¨ì–´)...")

    # ê³µì¶œí˜„ ê·¸ë˜í”„ ìƒì„±
    word_graph = graph_service.build_complete_graph(
        top_n=top_n,
        exclude_stopwords=True,
        max_length=-1
    )

    print(f"âœ“ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ")
    print(f"  - ë…¸ë“œ ìˆ˜: {word_graph.num_nodes}")
    print(f"  - ì—£ì§€ ìˆ˜: {word_graph.num_edges}")

    return word_graph


def set_node_features(graph_service: GraphService, word_graph: WordGraph,
                      method: str = 'concat', embed_size: int = 64) -> torch.Tensor:
    """
    ë…¸ë“œ íŠ¹ì„± ê³„ì‚° ë° ì„¤ì •

    Args:
        graph_service: GraphService ì¸ìŠ¤í„´ìŠ¤
        word_graph: íŠ¹ì„±ì„ ì„¤ì •í•  WordGraph
        method: ì„ë² ë”© ë°©ë²• ('concat', 'w2v', 'bert')
        embed_size: ì´ ì„ë² ë”© í¬ê¸°

    Returns:
        ê³„ì‚°ëœ ë…¸ë“œ íŠ¹ì„± í…ì„œ
    """
    print(f"\nğŸ¯ ë…¸ë“œ íŠ¹ì„± ê³„ì‚° ì¤‘ (method={method}, embed_size={embed_size})...")

    # NodeFeatureHandler ì‚¬ìš©
    node_handler = NodeFeatureHandler(graph_service.doc_service)

    # ì„ë² ë”© ê³„ì‚°
    if method == 'concat':
        print("  - Word2Vec + BERT concatenation")
    elif method == 'w2v':
        print("  - Word2Vec only")
    elif method == 'bert':
        print("  - BERT only")

    node_features = node_handler.calculate_embeddings(
        word_graph.words,
        method=method,
        embed_size=embed_size
    )

    print(f"âœ“ ë…¸ë“œ íŠ¹ì„± ê³„ì‚° ì™„ë£Œ: {node_features.shape}")

    # WordGraphì— íŠ¹ì„± ì„¤ì •
    word_graph.set_node_features_custom(node_features, NodeFeatureType.CUSTOM)
    print("âœ“ WordGraphì— ë…¸ë“œ íŠ¹ì„± ì„¤ì • ì™„ë£Œ")

    return node_features


def train_graphmae(graph_service: GraphService, word_graph: WordGraph,
                   epochs: int = 10, device: str = None) -> torch.Tensor:
    """
    GraphMAE ì‚¬ì „í•™ìŠµ ë° ì„ë² ë”© ì¶”ì¶œ

    Args:
        graph_service: GraphService ì¸ìŠ¤í„´ìŠ¤
        word_graph: í•™ìŠµí•  WordGraph (ë…¸ë“œ íŠ¹ì„±ì´ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•¨)
        epochs: í•™ìŠµ ì—í¬í¬ ìˆ˜
        device: í•™ìŠµ ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu', Noneì´ë©´ ìë™ ì„ íƒ)

    Returns:
        í•™ìŠµëœ GraphMAE ì„ë² ë”© [num_nodes, embed_size]
    """
    print(f"\nğŸš€ GraphMAE ì‚¬ì „í•™ìŠµ ì‹œì‘...")

    # ë…¸ë“œ íŠ¹ì„±ì´ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if word_graph.node_features is None:
        raise ValueError("WordGraphì— ë…¸ë“œ íŠ¹ì„±ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. set_node_features()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

    embed_size = word_graph.node_features.shape[1]
    print(f"  - ì…ë ¥ ì°¨ì›: {embed_size}")
    print(f"  - ë…¸ë“œ ìˆ˜: {word_graph.num_nodes}")
    print(f"  - ì—£ì§€ ìˆ˜: {word_graph.num_edges}")

    # GraphMAE ì„¤ì •
    config = GraphMAEConfig.create_default(embed_size)
    config.max_epochs = epochs
    config.device = device or ("cuda" if torch.cuda.is_available() else "cpu")

    print(f"âœ“ í•™ìŠµ ì„¤ì •: {config.max_epochs} epochs, device: {config.device}")
    if torch.cuda.is_available() and config.device == "cuda":
        print(f"  - GPU: {torch.cuda.get_device_name(0)}")

    # GraphMAE ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    mae_service = GraphMAEService(graph_service, config)

    # DGL ê·¸ë˜í”„ë¡œ ë³€í™˜ (ì´ë¯¸ ì„¤ì •ëœ ë…¸ë“œ íŠ¹ì„± ì‚¬ìš©)
    dgl_graph = graph_service.wordgraph_to_dgl(word_graph, word_graph.node_features)

    # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
    mae_service.model = mae_service.create_mae_model(embed_size)
    device_obj = torch.device(config.device)
    mae_service.model.to(device_obj)
    dgl_graph = dgl_graph.to(device_obj)

    optimizer = torch.optim.Adam(
        mae_service.model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay
    )

    # í•™ìŠµ ë£¨í”„
    mae_service.model.train()
    for epoch in range(config.max_epochs):
        optimizer.zero_grad()
        x = dgl_graph.ndata['feat']
        loss = mae_service.model(dgl_graph, x, epoch=epoch)
        loss.backward()
        optimizer.step()

        if (epoch + 1) % max(1, config.max_epochs // 10) == 0:
            print(f"  Epoch {epoch + 1}/{config.max_epochs}, Loss: {loss.item():.4f}")

    # ì„ë² ë”© ì¶”ì¶œ
    mae_service.model.eval()
    with torch.no_grad():
        embeddings = mae_service.model.embed(dgl_graph, dgl_graph.ndata['feat'])

    print(f"âœ“ GraphMAE í•™ìŠµ ì™„ë£Œ: {embeddings.shape}")
    return embeddings.cpu()


def analyze_results(original_features: torch.Tensor, mae_embeddings: torch.Tensor,
                   word_graph: WordGraph) -> None:
    """
    ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥

    Args:
        original_features: ì›ë³¸ íŠ¹ì„±
        mae_embeddings: GraphMAE ì„ë² ë”©
        word_graph: WordGraph ê°ì²´
    """
    print(f"\nğŸ“ˆ ê²°ê³¼ ë¶„ì„...")

    print(f"ì›ë³¸ íŠ¹ì„± í˜•íƒœ: {original_features.shape}")
    print(f"GraphMAE ì„ë² ë”© í˜•íƒœ: {mae_embeddings.shape}")

    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì²« 10ê°œ ë‹¨ì–´)
    from torch.nn.functional import cosine_similarity

    print(f"\nìƒìœ„ 10ê°œ ë‹¨ì–´ì˜ ì›ë³¸ vs GraphMAE ì½”ì‚¬ì¸ ìœ ì‚¬ë„:")
    print("-" * 50)

    for i in range(min(10, len(word_graph.words))):
        word = word_graph.words[i]
        orig_vec = original_features[i].unsqueeze(0)
        mae_vec = mae_embeddings[i].unsqueeze(0)

        similarity = cosine_similarity(orig_vec, mae_vec).item()
        print(f"{word.content:<15} {similarity:.4f}")

    # ì„ë² ë”© í†µê³„
    print(f"\nGraphMAE ì„ë² ë”© í†µê³„:")
    print(f"  í‰ê· : {mae_embeddings.mean().item():.4f}")
    print(f"  í‘œì¤€í¸ì°¨: {mae_embeddings.std().item():.4f}")
    print(f"  ìµœì†Ÿê°’: {mae_embeddings.min().item():.4f}")
    print(f"  ìµœëŒ“ê°’: {mae_embeddings.max().item():.4f}")


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ë…¼ë¬¸ íë¦„ì— ë§ì¶˜ íŒŒì´í”„ë¼ì¸

    íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ë¡œë“œ
    2. ë¬¸ì„œ ì „ì²˜ë¦¬ (DocumentService)
    3. ê³µì¶œí˜„ ê·¸ë˜í”„ ìƒì„± (ìƒìœ„ Nê°œ ë‹¨ì–´)
    4. ë…¸ë“œ íŠ¹ì„± ê³„ì‚° (Word2Vec + BERT concat)
    5. GraphMAE ì‚¬ì „í•™ìŠµ
    6. í•™ìŠµëœ ì„ë² ë”© ì¶”ì¶œ
    7. (ë‹¤ìŒ ë‹¨ê³„: í´ëŸ¬ìŠ¤í„°ë§)
    """
    print("ğŸ‰ GraphMAE íŒŒì´í”„ë¼ì¸ ì‹œì‘!")
    print("=" * 80)

    try:
        # ===== 1. ë°ì´í„°ì…‹ ë¡œë“œ =====
        csv_path = "/home/jaehun/lab/SENTIMENT/kaggle_RC_2019-05.csv"
        documents = load_dataset(csv_path, num_documents=500)

        # ===== 2. ë¬¸ì„œ ì „ì²˜ë¦¬ ë° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” =====
        graph_service = create_graph_service(documents)

        # ===== 3. ê³µì¶œí˜„ ê·¸ë˜í”„ ìƒì„± =====
        top_n = 500
        word_graph = build_cooccurrence_graph(graph_service, top_n=top_n)

        # ===== 4. ë…¸ë“œ íŠ¹ì„± ê³„ì‚° (Word2Vec + BERT concat) =====
        embed_size = 64
        node_features = set_node_features(
            graph_service,
            word_graph,
            method='concat',  # Word2Vec + BERT
            embed_size=embed_size
        )

        # ===== 5. GraphMAE ì‚¬ì „í•™ìŠµ =====
        epochs = 10  # í…ŒìŠ¤íŠ¸ìš© ì§§ì€ í•™ìŠµ
        graphmae_embeddings = train_graphmae(
            graph_service,
            word_graph,
            epochs=epochs,
            device=None  # ìë™ ì„ íƒ (CUDA ìš°ì„ )
        )

        # ===== 6. ê²°ê³¼ ë¶„ì„ =====
        print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"  - ì›ë³¸ ë…¸ë“œ íŠ¹ì„±: {node_features.shape}")
        print(f"  - GraphMAE ì„ë² ë”©: {graphmae_embeddings.shape}")

        analyze_results(node_features, graphmae_embeddings, word_graph)

        print("\n" + "=" * 80)
        print("ğŸŠ GraphMAE íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("=" * 80)
        print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: í´ëŸ¬ìŠ¤í„°ë§ (K-Means, DBSCAN ë“±)")

    except Exception as e:
        print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()