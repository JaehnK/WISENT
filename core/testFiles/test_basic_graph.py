"""
ê¸°ë³¸ ê·¸ë˜í”„ ìƒì„± í…ŒìŠ¤íŠ¸ (DGL ì—†ì´)
- kaggle_RC_2019-05.csv ë°ì´í„°ì…‹ ì‚¬ìš©
- ìƒìœ„ 500ê°œ ë‹¨ì–´ë¡œ ê³µì¶œí˜„ ê·¸ë˜í”„ ìƒì„±
- Word2Vec(32) + BERT(32) = 64ì°¨ì› concat íŠ¹ì„±
"""

import os
import sys
import pandas as pd
import torch
from typing import List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# í•„ìš”í•œ ëª¨ë“ˆë“¤ import
from services.Document.DocumentService import DocumentService
from services.Graph.GraphService import GraphService
from services.Graph.NodeFeatureHandler import NodeFeatureHandler
from entities import Word, WordGraph, NodeFeatureType


def load_dataset(csv_path: str, num_documents: int = 100) -> List[str]:
    """CSV ë°ì´í„°ì…‹ ë¡œë“œ"""
    print(f"ğŸ“ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘: {csv_path}")

    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")

    df = pd.read_csv(csv_path)
    print(f"âœ“ ì „ì²´ ë°ì´í„° í¬ê¸°: {len(df)} í–‰")

    if 'body' not in df.columns:
        raise ValueError("CSV íŒŒì¼ì— 'body' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    documents = df['body'].dropna().head(num_documents).tolist()
    print(f"âœ“ ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(documents)}")

    return documents


def test_basic_graph():
    """ê¸°ë³¸ ê·¸ë˜í”„ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("ğŸ‰ ê¸°ë³¸ ê·¸ë˜í”„ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    print("=" * 50)

    try:
        # 1. ë°ì´í„°ì…‹ ë¡œë“œ
        csv_path = "/home/jaehun/lab/SENTIMENT/kaggle_RC_2019-05.csv"
        documents = load_dataset(csv_path, num_documents=100)

        # 2. DocumentService ì´ˆê¸°í™”
        print("\nğŸ”§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        doc_service = DocumentService()
        print("âœ“ DocumentService ì´ˆê¸°í™” ì™„ë£Œ")

        # 3. ë¬¸ì„œ ì²˜ë¦¬
        doc_service.create_sentence_list(documents=documents)
        print(f"âœ“ ë¬¸ì¥ ì²˜ë¦¬ ì™„ë£Œ - {doc_service.get_sentence_count()}ê°œ ë¬¸ì¥")

        # ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ëŠ” ë¬¸ì¥ ì²˜ë¦¬ ì‹œ ìë™ìœ¼ë¡œ ìƒì„±ë¨
        top_words = doc_service.get_top_words(100)
        print(f"âœ“ ë‹¨ì–´ ì²˜ë¦¬ ì™„ë£Œ - ìƒìœ„ {len(top_words)}ê°œ ë‹¨ì–´")

        # 4. GraphService ì´ˆê¸°í™”
        graph_service = GraphService(doc_service)
        print("âœ“ GraphService ì´ˆê¸°í™” ì™„ë£Œ")

        # 5. ê³µì¶œí˜„ ê·¸ë˜í”„ ìƒì„±
        print(f"\nğŸ“Š ê³µì¶œí˜„ ê·¸ë˜í”„ ìƒì„± ì¤‘ (ìƒìœ„ 50ê°œ ë‹¨ì–´)...")
        word_graph = graph_service.build_complete_graph(
            top_n=50,  # ì‘ì€ ìˆ˜ë¡œ í…ŒìŠ¤íŠ¸
            exclude_stopwords=True,
            max_length=-1
        )

        print(f"âœ“ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ")
        print(f"  - ë…¸ë“œ ìˆ˜: {word_graph.num_nodes}")
        print(f"  - ì—£ì§€ ìˆ˜: {word_graph.num_edges}")

        # 6. NodeFeatureHandler í…ŒìŠ¤íŠ¸
        print(f"\nğŸ¯ ë…¸ë“œ íŠ¹ì„± í…ŒìŠ¤íŠ¸ ì¤‘...")
        node_handler = NodeFeatureHandler(graph_service.doc_service)

        # Word2Vec íŠ¹ì„± í…ŒìŠ¤íŠ¸
        print("Word2Vec íŠ¹ì„± ê³„ì‚° ì¤‘...")
        try:
            w2v_features = node_handler.calculate_embeddings(
                word_graph.words[:5],  # ì²˜ìŒ 5ê°œ ë‹¨ì–´ë§Œ
                method='w2v',
                embed_size=32
            )
            print(f"âœ“ Word2Vec íŠ¹ì„±: {w2v_features.shape}")
        except Exception as e:
            print(f"âŒ Word2Vec ì‹¤íŒ¨: {e}")
            return

        # BERT íŠ¹ì„± í…ŒìŠ¤íŠ¸
        print("BERT íŠ¹ì„± ê³„ì‚° ì¤‘...")
        try:
            bert_features = node_handler.calculate_embeddings(
                word_graph.words[:5],  # ì²˜ìŒ 5ê°œ ë‹¨ì–´ë§Œ
                method='bert',
                embed_size=64  # BERTëŠ” embed_size ë¬´ì‹œ
            )
            print(f"âœ“ BERT íŠ¹ì„±: {bert_features.shape}")
        except Exception as e:
            print(f"âŒ BERT ì‹¤íŒ¨: {e}")
            return

        # Concat íŠ¹ì„± í…ŒìŠ¤íŠ¸
        print("Concat íŠ¹ì„± ê³„ì‚° ì¤‘...")
        try:
            concat_features = node_handler.calculate_embeddings(
                word_graph.words[:5],  # ì²˜ìŒ 5ê°œ ë‹¨ì–´ë§Œ
                method='concat',
                embed_size=64
            )
            print(f"âœ“ Concat íŠ¹ì„±: {concat_features.shape}")
        except Exception as e:
            print(f"âŒ Concat ì‹¤íŒ¨: {e}")
            return

        # 7. WordGraphì— íŠ¹ì„± ì„¤ì • í…ŒìŠ¤íŠ¸
        print(f"\nğŸ”§ WordGraph íŠ¹ì„± ì„¤ì • í…ŒìŠ¤íŠ¸...")
        all_concat_features = node_handler.calculate_embeddings(
            word_graph.words,
            method='concat',
            embed_size=64
        )

        word_graph.set_node_features_custom(all_concat_features, NodeFeatureType.CUSTOM)
        print(f"âœ“ ë…¸ë“œ íŠ¹ì„± ì„¤ì • ì™„ë£Œ: {word_graph.node_features.shape}")

        # 8. ìƒìœ„ ë‹¨ì–´ë“¤ ì¶œë ¥
        print(f"\nğŸ“‹ ìƒìœ„ 10ê°œ ë‹¨ì–´:")
        for i, word in enumerate(word_graph.words[:10]):
            print(f"  {i+1:2d}. {word.content:<15} (ë¹ˆë„: {word.freq})")

        print("\nğŸŠ ê¸°ë³¸ ê·¸ë˜í”„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 50)

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_basic_graph()