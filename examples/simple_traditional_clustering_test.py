"""
Traditional Graph Clustering ê°„ë‹¨ í…ŒìŠ¤íŠ¸

GRACE ì—†ì´ ì „í†µì  ê·¸ë˜í”„ í´ëŸ¬ìŠ¤í„°ë§ë§Œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
from pathlib import Path
import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'core'))

from services.GRACE import TraditionalGraphClusteringService
from services.Document import DocumentService
from services.Graph import GraphService


def main():
    print("=" * 80)
    print("ğŸ”¬ Traditional Graph Clustering í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ì„¤ì •
    csv_path = '/home/jaehun/lab/SENTIMENT/kaggle_RC_2019-05.csv'
    num_documents = 10000
    top_n_words = 500
    text_column = 'body'
    
    print(f"\nğŸ“Š ì„¤ì •:")
    print(f"  - ë¬¸ì„œ ìˆ˜: {num_documents}")
    print(f"  - ë…¸ë“œ ìˆ˜: {top_n_words}")
    
    # Step 1: ë°ì´í„° ì „ì²˜ë¦¬
    print("\n[1/4] ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬...")
    
    # CSV ë¡œë“œ (run_grace_visualization.py íŒ¨í„´)
    df = pd.read_csv(csv_path)
    print(f"  ì „ì²´ ë°ì´í„°: {len(df)} í–‰")
    
    if text_column not in df.columns:
        raise ValueError(f"CSVì— '{text_column}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {df.columns.tolist()}")
    
    # ë¬¸ì„œ ì¶”ì¶œ
    documents = df[text_column].dropna().head(num_documents).tolist()
    print(f"  ë¡œë“œëœ ë¬¸ì„œ: {len(documents)}ê°œ")
    
    # DocumentService ì´ˆê¸°í™” ë° ì „ì²˜ë¦¬
    doc_service = DocumentService()
    doc_service.create_sentence_list(documents=documents)
    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ")
    print(f"  - ë¬¸ì¥: {doc_service.get_sentence_count()}ê°œ")
    print(f"  - ë‹¨ì–´: {len(doc_service.words_list) if doc_service.words_list else 0}ê°œ")
    
    # Step 2: ì˜ë¯¸ì—°ê²°ë§ êµ¬ì¶•
    print("\n[2/4] ì˜ë¯¸ì—°ê²°ë§ êµ¬ì¶•...")
    graph_service = GraphService(doc_service)
    word_graph = graph_service.build_complete_graph(
        top_n=top_n_words,
        exclude_stopwords=True
    )
    print(f"âœ… ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ:")
    print(f"   - ë…¸ë“œ: {word_graph.num_nodes}")
    print(f"   - ì—£ì§€: {word_graph.num_edges}")
    
    # Step 3: ì „í†µì  í´ëŸ¬ìŠ¤í„°ë§
    print("\n[3/4] í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰...")
    traditional = TraditionalGraphClusteringService(random_state=42)
    
    # Louvain
    print("\nğŸ”µ Louvain:")
    louvain_labels, louvain_metrics = traditional.louvain_clustering(word_graph)
    print(f"   í´ëŸ¬ìŠ¤í„° ìˆ˜: {louvain_metrics['num_clusters']}")
    print(f"   Modularity: {louvain_metrics['modularity']:.4f}")
    
    # í´ëŸ¬ìŠ¤í„° ë¶„í¬
    distribution = traditional.get_cluster_distribution()
    print(f"   í´ëŸ¬ìŠ¤í„° ë¶„í¬: {distribution}")
    
    # Leiden (ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´)
    print("\nğŸŸ¢ Leiden:")
    try:
        leiden_labels, leiden_metrics = traditional.leiden_clustering(word_graph)
        print(f"   í´ëŸ¬ìŠ¤í„° ìˆ˜: {leiden_metrics['num_clusters']}")
        print(f"   Modularity: {leiden_metrics['modularity']:.4f}")
    except ImportError as e:
        print(f"   âš ï¸  ìŠ¤í‚µ (íŒ¨í‚¤ì§€ ì—†ìŒ): {e}")
    
    # Step 4: í´ëŸ¬ìŠ¤í„° ë‹¨ì–´ ì¶œë ¥
    print("\n[4/4] í´ëŸ¬ìŠ¤í„° ë¶„ì„...")
    print("\nìƒìœ„ 3ê°œ í´ëŸ¬ìŠ¤í„°ì˜ ëŒ€í‘œ ë‹¨ì–´:")
    
    # Louvain ê²°ê³¼ ì‚¬ìš©
    traditional.cluster_labels = louvain_labels
    traditional.num_clusters = louvain_metrics['num_clusters']
    
    num_clusters_to_show = min(3, traditional.num_clusters)
    
    for cluster_id in range(num_clusters_to_show):
        words = traditional.get_cluster_words(word_graph, cluster_id, top_n=10)
        print(f"\nğŸ“Œ Cluster {cluster_id} (í¬ê¸°: {distribution.get(cluster_id, 0)}):")
        print(f"   {', '.join([w for w, _ in words])}")
    
    # ê·¸ë˜í”„ í†µê³„
    print("\nğŸ“Š ê·¸ë˜í”„ í†µê³„:")
    stats = traditional.compute_graph_statistics()
    print(f"   - ë°€ë„: {stats['density']:.4f}")
    print(f"   - í‰ê·  ì°¨ìˆ˜: {stats['average_degree']:.2f}")
    print(f"   - ì—°ê²°ë¨: {stats['is_connected']}")
    if not stats['is_connected']:
        print(f"   - ì—°ê²° ì„±ë¶„ ìˆ˜: {stats['num_connected_components']}")
    
    # ê²°ê³¼ ì €ì¥
    print("\nğŸ’¾ ê²°ê³¼ ì €ì¥...")
    output_dir = Path('./traditional_clustering_output')
    output_dir.mkdir(exist_ok=True)
    
    traditional.save_clustering_results(
        word_graph,
        output_path=str(output_dir / 'louvain_results.json'),
        include_words=True
    )
    
    print("\n" + "=" * 80)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   1. GRACEì™€ ë¹„êµ: python examples/compare_grace_with_traditional.py")
    print(f"   2. ê²°ê³¼ í™•ì¸: {output_dir}/louvain_results.json")


if __name__ == '__main__':
    main()
